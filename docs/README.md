# 大数据

> 大数据的关键词：
>
> ​		吞吐量，延迟，并发，传输速度，io，容错性，扩展性，健壮性，持久化，弹性扩展。
>
> 离线，实时
>
> 时效性。
>
> 数据一致性，



## 分布式：





## 离线计算：

> 离线计算一般指通过批处理的方式计算**已经存储至文件，数据库的数据**（不会产生变化）。
>
> 特点：
>
> + 数据不会发生变化
>
> + 计算量级较大，保存时间长
> + 计算时间较长
> + 对时效性不敏感

场景：

计算前一天积累的日志在凌晨进行计算。



## 实时计算：

> 实时计算一般是通过流处理方式计算当日数据（正在产生的数据）。
>
> 这种数据是会发生变化的。
>
> 准实时计算，采用的框架是Spark等，微批次进行处理。
>
> 特点：
>
> + 局部计算【以单条，微批次，小窗口数据范围进行计算】
> + 消耗资源成本高【24小时不间断运行】
> + 时效性
> + 可视化性
> + 开发成本【不能写sql，需要写代码】
>
> 

实时计算不能基于全部数据进行统计排序分组，只能对小窗口，微批次进行排序。





# 数据库

## OLTP(联机事务处理系统)：

>  与功能、业务强相关的事务查询系统，要保证高并发场景下低时延的查询和处理效率，因此对CPU的性能要求较高 
>
>  存储的是业务数据，记录某类业务事件的发生，such as : 下单，注册，支付等等 
>
> 代表：mysql
>
>  **数据量相对较少，是GB级别的，面向业务开发人员** 

结构化数据，半结构化数据.....

事务

acid

一致性





分布式锁

乐观锁，悲观锁

1）基于数据库实现

2）基于redis缓存实现

3）基于zookeeper实现







时间

mysql中使用timestamp，默认值为当前时间

使用datetime，默认值是null





## 数据库和数据仓库的比较：



**数据库侧重 事务和查询**

**数据仓库侧重于分析。**

> 数据库用于快速事务处理和实时查询，而数据仓库用于综合分析、历史数据分析和复杂查询 

为什么需要数据库：

1. **事务处理**：数据库主要用于支持事务处理（OLTP），它们专注于实时的数据录入、更新和查询。数据库设计和优化针对高并发、低延迟的操作，更适合支持日常的业务活动和交易处理。
2. **实时查询**：数据库通常用于快速的实时查询，提供即时的响应时间，以满足对当前数据的操作和分析需求。





为什么需要数据仓库：

1. 综合性分析： 数据仓库是一个综合的数据存储解决方案，用于集成和整理来自多个数据源的数据 ，提供海量数据的支持
2. 历史数据分析：存储了历史数据，便于用户在时间上分析。
3. 复杂分析需求：数据仓库支持复杂查询、多维分析和高性能数据挖掘。它们提供了强大的聚合、切片和钻取功能，以更好地理解和利用数据。

> 简化就是，数据仓库提供历史数据，和多个数据源的数据并支持复杂功能进行数据分析。







# 数据仓库

存储大规模数据，用于支持决策和分析的数据存储解决方案。

## OLAP(联机分析处理系统)：

> 存储**多业务历史**数据，支持复杂的分析操作，侧重决策，并且提供直观易懂的查询结果。
>
> 代表：
>
> hive，clickhouse，elasticSearch
>
>  **数据量大，常规是TB级别的，面向分析决策人员** 



## 模型方法论

### ER模型

实体-关系模型，遵循范式，冗余性低，但是查询时会





事实表：

 事实表是数据仓库中存储**度量数据**（measurements）的主要表 ，其数据一般是可变的。

维度表：

 维度表是数据仓库中存储业务过程中的**描述性数据**（descriptive data）的表 ，数据通常是静态的，不经常发生变化。



> 事实表存储了度量数据，用于度量和计量业务过程，而维度表存储了描述性数据，提供了上下文和筛选条件。它们通过关联和共享键来构建数据仓库中的数据模型，支持复杂的数据分析和报告。 



> 事实表：
>
> + 事务事实表【增量同步】
>
> + 周期快照事实表【全量同步】
>
> + 累积快照事实表【全量同步】
>
>   【后面这两个表可能存在也可能不存在，这俩是解决事务事实表缺点的方案】



> 维度表：
>
> 维度退化： 指的是直接把一些简单的维度放在事实表中 

### 维度模型



### 1.1星型模型

 当所有维表都直接连接到 **“事实表”** 上时，整个图解就像星星一样，故将该模型称为星型模型 。

> 星型架构是一种**非正规化**的结构，多维数据集的每一个维度都直接与事实表相连接，**不存在渐变维度**，所以**数据有一定的冗余**。 



### 1.2雪花模型







### 1.3星座模型

又称星系模型







## 为什么要分层

https://baijiahao.baidu.com/s?id=1771016309102798991&wfr=spider&for=pc













# 离线项目

![img](E:\Typora\typora-images\wps1-1694235528512.png)













# 实时项目









# Hive





























# flume

> flume是一种分布式的数据采集和传输系统。







# Kafka

> 2.8版本以后可以不采取zk了。
>
> 0.9版本之前offset信息保存到zk，0.9之后offset存储在kafka的主题中

定义：

Kafka是一个**分布式**的基于发布/订阅模式的**消息队列**，分布式事件流平台。

应用场景：

+ 缓冲/消峰：当某一时刻，大量数据到来时，kafka可以解决生产，消费对消息处理速度不一致的问题【将消费不掉的数据存储到kafka中】。
+ 解耦：通过kafka作为中间媒介，让两端的组件遵守同样的接口约束即可。
+ 异步通信：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。

消息队列的两种模式：

+ 点对点【消费者主动拉取数据，消息收到后删除消息】，单播
+ 发布/订阅模式【通过订阅主题，主动将数据推送给订阅着，消费者消费数据后，不删除数据】，广播

> 二者的区别在于：
>
> 0）是否为单播（一个消息只能被一个接受者处理）
>
> 1）消费完数据后是否删除数据
>
> 2）一个是推送，一个是拉取





![1694239682191](E:\Typora\typora-images\1694239682191.png)

> ids/[0,1,2]:代表zk集群中的broker节点



>  /brokers/topics/first/partitions/0/state "leader":0,"isr":[0,2] 
>
> - "leader": 0，表示该分区的当前 Leader 副本所在的 Broker ID 是 0。
> - "isr": [0,2]，表示该分区的当前处于同步副本集（In-Sync Replicas，简称 ISR）中的 Broker ID 列表是 [0, 2]。ISR 中的副本与 Leader 副本保持同步，可以参与消息的复制和处理。

## kafka的基础架构有哪些

1. producer
2. consumer
3. broker
4. consumer group（CG）：由多个消费者组成，每个消费者负责消费不同分区的数据，一个分区只能被组内的一个消费者消费，但是消费者组之间互不影响
5. topic
6. partition：一个topic可以分为多个分区，默认为1个，每个分区内都是一个有序的队列。
7. leader
8. flower
9. zookeeper
10. replica：每个分区都有若干个副本，默认一个分区有 一个副本【即，一个leader+0个或多个follower副本】。

> 针对leader和flower：
>
> flower是主动从leader中拉取数据







## kafka怎样保证数据精确一次传输

### 生产端

1）使用事务（影响性能）

使用kafka提供的事务【需要先配置并开启事务日志，并且**开启幂等性**】+消费端支持事务

![1694262134315](E:\Typora\typora-images\1694262134315.png)

2）幂等【下游组件】+至少一次【核心：可以重复消费，但是下游只对重复数据处理一次】

开启参数 **enable.idempotence** 默认为 true，false 关闭

开启幂等后，kafka服务端会缓存生产者发来的五个request的元数据【可以保证这五个是有序的】

> 幂等性：指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复

>**重复数据的判断标准**：具有<PID, Partition, SeqNumber>相同主键的消息提交时，Broker只会持久化一条。其 中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。



> **所以幂等性只能保证的是在单分区单会话内不重复。**
>
>使用事务可以保证数据在分区间，多会话 内数据不重复



### 消费端

![1694316644056](E:\Typora\typora-images\1694316644056.png)









## 数据有序

分区内有序，分区间无序

如果需要有序，放到同一个分区

> 想要有序的前提，必须是单分区
>
> 如何保证单分区内数据有序？
>
> 1）设置retries=0，禁止重试【重试会导致乱序。可能会导致数据丢失】
>
> 2）启用幂等
>
> + 设置enable.idempotence=true，启用幂等
> + 设置max.in.flight.requests.per.connection，1.0.X之后，小于等于5
> + 设置retries，保证其大于0
> + 设置acks，保证其为-1











## kafka负载均衡

生产端，通过分区，指定分区，指定key，自定义分区等

broker，通过自动副本平衡，topic分区







## 数据积压（消费者如何提高吞吐量）

1）kafka 消费能力不足

+ 增加Topic分区数
+ 同时提升消费组的消费者数量。

> 二者需要同时满足，不然并发还是没有提升

2）下游数据处理不及时

+ 提高每批次最大拉取的数据50M【批次拉取过少，导致拉取速度<生产速度，导致积压】
+ 提高拉取数据返回消息的最大条数500条。





## 数据重复问题

> 如果想要kafka保证数据不重复：
>
> 去重=幂等性+事务【但是代价太高】
>
> 解决方式：至少一次+幂等性【这个幂等可能就交给下游完成了】

事务 + 手动提交 offset （enable.auto.commit = false）。 

消费者输出的目的地必须支持事务（MySQL、Kafka）。





1）生产者端

![1694325406553](E:\Typora\typora-images\1694325406553.png)

2）broker端

Leader挂机，只能保证副本数据的一致性，并不能保证不丢失，或不重复



## 采集数据为什么选择kafka

采集层主要可以使用Flume，kafka等技术

Flume：flume是管道流方式，提供很多的默认实现，让用户通过参数部署，以及扩展API。

kafka：kafka是一个可持久化的分布式的消息队列，是一个非常通用的系统。



flume不支持副本事件。



> 二者可以结合使用.
>
> Flume 是一个专注于数据采集和传输的工具，旨在解决实时数据流的收集、过滤和传输问题。Flume 侧重于低延迟、高吞吐量的实时数据传输，以及对日志和事件数据的处理。
>
> 而消息队列（如 Kafka）则是更通用的消息传递系统，旨在**实现可靠的、分布式的消息传输和存储**。可以**支持多个消费者同时订阅相同的消息流**。消息队列通常被用于构建异步通信系统、事件驱动架构、实时流处理等场景。



应用场景：

kafka:

+ 适用于高吞吐量，低延迟的工作负载
+ 解耦消息发送和接收者，因为发送方不需要等待返回值
+ 消息队列
+ 实时流处理



flume：

+ 日志收集和分析
+ 对一些数据进行etl处理的情况
+ 数据采集和传输



>数据被多个系统消费的话，使用 kafka；如果数据被设计给 Hadoop 使用，使用 Flume。



flume的扩展性不行，而kafka提供了强大的扩展api





## 生产者

### 流程

涉及两个线程：

+ main线程
+ Sender线程

同步发送流程

![1694242115310](E:\Typora\typora-images\1694242115310.png)

**InFlightRequests，默认每个 Broker最多缓存5个请求**【保证这5个请求都是有序的】 ，

> 客户端通过**发送元数据请求**来获取集群的主题等基本信息。
>
> 双端队列RecordAccumulator
>
> main 线程将消息发送给 RecordAccumulator， 
>
> Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka Broker。 

|                    |                                                              |
| ------------------ | ------------------------------------------------------------ |
| buffer.memory      | RecordAccumulator 缓冲区总大小，**默认 32m**。               |
| batch.size         | 缓冲区一批数据最大值，**默认 16k**。                         |
| linger.ms          | 默认值为***0ms***，表示不启用这个                            |
| enable.idempotence | 是否开启幂等。默认开启幂                                     |
| compression.type   | 生产者发送的所有数据的压缩方式。默认是 none，也 就是不支持压缩，支持压缩类型：none，gzip，snappy，lz4和zstd |
| retries            | 当消息发送出现错误的时候，系统会重发消息。retries 表示重试次数。默认是 int 最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1 |



### 同步发送和异步发送







### 生产者为什么要分区，有哪些分区策略

> + 提高并行度，供消费者组以分区为单位消费
> + 负载均衡



分区策略:

> 1）指定特定分区【场景：数据全局有序时需要将数据发往同一个分区】
>
> 2）没有partition值（未指定分区）但是存在key值：
>
> 将key的hash值与topic的partition数进行取余得到partition值。
>
> 3）既没有分区值也没有key值，采用Sticky Partition（粘性分区器），会**随机选择一个分区**，并尽可能一直使用该分区（直到当前batch或者linger的时间到了），再选择其他分区【如果选到之前用到的，还会重新随机选取】
>
> 4）自定义分区
>
> + （1）定义类实现 Partitioner 接口。实现 implements Partitioner
>
> + （2）重写 partition()方法。 
>
> + （3）使用分区器的方法，在生产者的配置中添加分区器参数。 properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,"com.atgui 
>
>   gu.kafka.producer.MyPartitioner"); 



```java
指定分区，此时key是“”空字符
kafkaProducer.send(new ProducerRecord<>("first", 
1,"","atguigu " + i), new Callback() {}
指定key，此时的分区参数没有了
kafkaProducer.send(new ProducerRecord<>("first", 
"a","atguigu " + i), new Callback() {            
```





### 生产者如何提高吞吐量

+ 提高batch.size的值，默认16k，可以提高吞吐量【不能太大，会导致数据传输延迟增加】
+ linger.ms：等待时间，修改为5-100ms
+ 增加缓冲区大小，默认32M，修改为64M
+ 使用压缩，snappy压缩效果好，使数据量减少



### 生产者的ack应答是怎么回事

> ISR队列： 指的是与主副本保持同步的副本集合。
>
>  只有处于ISR队列中的副本才会被认为是“活跃”节点，可以参与数据的复制和读写操作。
>
> 只有当ISR队列中的大多数副本确认接收并写入消息后，主副本才将消息标记为已提交。
>
> 如果副本无法与主副本保持同步，例如响应延迟过高【默认为30s】或发生故障，Kafka会将其移出ISR队列。这样可以确保只有可靠的、与主副本保持同步的副本参与数据的复制和读写操作。



> 副本包括主副本（Leader）和一组追随者副本（Followers）。**主副本负责处理读写请求**，而**追随者副本**负责**复制主副本的数据**。 



ack的应答级别有：

0：**生产者发送过来的数据，不需要等数据落盘应答**【至多一次】

1：**生产者发送过来的数据，不需要等数据落盘应答**

-1（all）：**生产者发送过来的数据，Leader和ISR队列里面的所有节点收齐数据后应答。** 【至少一次】



### 生产者端数据可靠性

**数据完全可靠条件** **=** **ACK级别设置为-1 +分区副本大于等于2 +ISR里应答的最小副本数量大于等于2**



**可靠性总结：** 

可靠性总结：
acks=0，生产者发送过来数据就不管了，可靠性差，效率高；
acks=1，生产者发送过来数据Leader应答，可靠性中等，效率中等；
acks=-1，生产者发送过来数据Leader和ISR队列里面所有Follwer应答，可靠性高，效率低；
在生产环境中，acks=0很少使用；acks=1，一般用于传输普通日志，允许丢个别数据；acks=-1，一般用于传输和钱相关的数据，
对可靠性要求比较高的场景。



**数据重复分析**：

当数据存储成功但是因为leader挂了等问题，导致-1未返回，会重新选举leader，重新发送一遍数据。























## broker

在zookeeper的服务端存储的Kafka相关信息： 

1）/kafka/brokers/ids [0,1,2] 记录有哪些服务器 

2）/kafka/brokers/topics/first/partitions/0/state 

{"leader":1 ,"isr":[1,0,2] } 记录谁是Leader，有哪些服务器可用

3）/kafka/controller  

{“brokerid”:0}  辅助选举Leader

![1694265678670](E:\Typora\typora-images\1694265678670.png)

1）broker启动后去zk注册

2）controller谁先注册是谁的

3）由选举的Controller监听brokers节点变化，并决定Leader的选举

4）Controller选举完上传节点信息到zk

5）如果某个leader挂了，Controller监听到节点变化，获取ISR，选举新的leader【在ISR中存活，再按照AR（该分区的所有副本统称）排在前面的优先】

6）更新leader及ISR。

### 重要参数

|                                         |                                                              |
| --------------------------------------- | ------------------------------------------------------------ |
| replica.lag.time.max.ms                 | 该时间阈值，**默认 30s**。ISR中，如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。 |
| auto.leader.rebalance.enable            | **默认是 true**。 自动 Leader Partition 平衡。               |
| leader.imbalance.per.broker.percentage  | **默认是 10%**。每个 broker 允许的不平衡的 leader 的比率，超过触发平衡 |
| leader.imbalance.check.interval.seconds | **默认值 300 秒**。检查 leader 负载是否平衡的间隔时间        |
| log.segment.bytes                       | 默认值 1G。segment的大小                                     |
| log.index.interval.bytes                | 默认 4kb。写入4kb的.log数据，就会生成一个索引。              |
| log.cleanup.policy                      | 默认是 delete，表示所有数据启用删除策略； 如果设置值为 compact，表示所有数据启用压缩策略。 |

> kafka中**数据默认保存7天**，分钟和秒默认关闭。
>
> 当数据过大，超过设置的日志大小，默认策略是删除最早的segment，来清理空间。



### 退役旧节点和服役新节点

服役：

1)创建要均衡的主题

2）生成一个负载均衡计划

bin/kafka-reassign-partitions.sh -- bootstrap-server hadoop102:9092 

--topics-to-move-json-file  topics-to-move.json【自定义的】 --broker-list "0,1,2,3" --generate 

3）创建副本存储计划【将上面返回的计划返回】

4）执行并验证

> 退役节点和服役节点差不多，在第2）步broker列表进行删除旧节点



### 讲述一下kafka的副本

作用是**提高数据可靠性**【太多副本会增加磁盘存储空间，**增加网络上数据传输**，降低效率】

在Kafka 分区中的所有副本统称为 AR（Assigned Repllicas）。 

AR = ISR + OSR

ISR：和leader保持同步的follower集合。

OSR：表示follower与leader副本同步时，延迟过多的副本

### 讲述Leader选举流程

Leader是由最先注册的broker以Controller身份选举出来的。

Controller Leader，负责管理集群 broker 的上下线，所有 **topic 的分区副本分配和 Leader 选举**等工作



### Leader和Follower故障处理细节

![1694270669518](E:\Typora\typora-images\1694270669518.png)

> 为了保证数据一致性，所以可能需要丢失或重复数据

![1694270792252](E:\Typora\typora-images\1694270792252.png)



### Leader Partition负载平衡

> 根据不平衡数推断不平衡率，满足后再进行再平衡

![1694272376143](E:\Typora\typora-images\1694272376143.png)



### kafka的文件采用什么存储机制

防止log文件过大，导致数据定位效率低下

采用：分片+索引

将每个partition分为多个segment，segment包括.index,.log,.timeindex(时间戳索引文件)文件，这些文件存在于一个文件夹segment下，命名规则：topic名称+分区号（myTopic-0）

> segment文件大小默认为1G，每4kb .log数据写一条索引
>
> 细节：
>
> index中，index的名是当前segment第一条数据绝对offset，而index数据中，存储的是相对offset

![1694273093516](E:\Typora\typora-images\1694273093516.png)



### kafka的文件清理策略

Kafka 中默认的日志保存时间为 7 天。

Kafka 中提供的日志清理策略有 delete 和 compact 两种。

1）delete 日志删除：将过期数据删除 【如果完全过期的数据，可以进行删除】

会出现情况：

一个segment中有很多数据，其中一部分数据过期了，一部分数据没有过期

上述数据其实是不能删除的，可以考虑使用压缩。

2）compact 日志压缩











### kafka数据存储在磁盘，为什么还说是高效

1）kafka是分布式集群，可以采用分区技术，并行度高

2）读数据采用稀疏索引，可以快速定位到要消费的数据

3）顺序写磁盘【一直追加数据到文件末端】

4）页缓存+零拷贝

> 页缓存：
>
>  不走应用层的主要原因是性能和效率方面的考虑。通过采用基于TCP协议的二进制协议，Kafka能够实现更高的吞吐量、更低的延迟和更好的可靠性。 
>
> Kafka之所以可以不用走应用层协议，是因为Kafka利用这种基于日志的存储方式和分区副本机制，使得消息可以持久化存储，并且能够提供高吞吐量和低延迟的消息传输。应用程序可以直接使用Kafka提供的API来发送和接收消息，而无需依赖于额外的通信层协议。
>
> 通过绕过应用层协议，Kafka在消息传递过程中减少了额外的开销，提高了传输效率。同时，Kafka还提供了一些高级特性，比如消息的批量处理和压缩，进一步提升了性能和效率。

> 零拷贝：
>
>  避免数据在不同缓冲区之间的拷贝操作来减少数据传输的开销 
>
>  传统的数据传输方式涉及多次数据拷贝，需要先将数据拷贝到应用程序的缓冲区，然后再从应用程序的缓冲区将数据拷贝到网络缓冲区。
>
> 这样的拷贝操作会增加CPU和内存的开销。而**零拷贝技术通过直接将数据从磁盘或网络缓冲区传输到目标缓冲区，避免了中间的拷贝操作**，减少了CPU和内存的使用，提高了数据传输的效率。 

![1694274693473](E:\Typora\typora-images\1694274693473.png)



## 消费者

> offset存储在broker的主题   __consumer_offsets[分区数为50]，
>
> __consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic+分区号，value 就是当前 offset 的值。每隔一段时间，kafka 内部会对这个 topic 进行compact【压缩】，也就是每个 group.id+topic+分区号就保留最新数据。 

> 消费者采取主动拉取数据的方式获取数据【如果使用push方式，broker的发送速率不好确定】

![1694309840791](E:\Typora\typora-images\1694309840791.png)

![1694310242163](E:\Typora\typora-images\1694310242163.png)

>1. 选举leader的算法通常基于以下几个因素进行评估：
>   - 活跃性：对于那些已经活跃地消费消息并保持连接的消费者来说，更有可能成为leader。
>   - **优先级**：如果消费者设置了优先级属性，那么具有更高优先级的消费者可能更容易成为leader。
>   - **顺序**：根据消费者加入组的先后顺序，先加入的消费者可能更有机会成为leader。

1)消费者组向coordinator发送JoinGroup请求

2）选出一个consumer作为leader

3）把要消费的topic情况发送给leader消费者

4)leader消费者制定消费方案

5）leader将消费方案发送给coordinator

6）coordinator将消费方案下发给各个consumer

7）每个消费者和coordinator保持心跳（默认3秒），一旦超时（session.timeout.ms=45s），消费者会被移除，并触发**再平衡**【topic副本也存在再平衡】，或者消费者处理消息的时间过长（max.poil.interval.ms 5分钟），也会触发再平衡。

![1694311253962](E:\Typora\typora-images\1694311253962.png)

超过50M，或者500ms，达到500条，会返回数据。



### 重要参数

|                         |                                                              |
| ----------------------- | ------------------------------------------------------------ |
| enable.auto.commit      | **默认值为 true**，消费者会自动周期性地向服务器提交偏移量    |
| auto.commit.interval.ms | 默认5s提交一次偏移量                                         |
| auto.offset.reset       | 当 Kafka 中没有初始偏移量或当前偏移量在服务器中不存在 （如，数据被删除了），该如何处理？ earliest：自动重置偏 移量到最早的偏移量。 latest：默认，自动重置偏移量为最新的偏移量。 none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。 anything：向消费者抛异常。 |
| heartbeat.interval.ms   | 消费者与coordinator之间的心跳为3s                            |
| session.timeout.ms      | Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超过该值，该消费者被移除，消费者组执行再平衡。 |
| max.poll.interval.ms    | 默认5分钟。消费者处理数据的最大时长，超过该值，消费者被移除，执行再平衡 |
| fetch.min.bytes         | 默认1字节，                                                  |
| fetch.max.wait.ms       | 500ms                                                        |
| fetch.max.bytes         | 50M                                                          |
| max.poll.records        | 500条                                                        |



























### 为什么设计消费者组

>使用消费者组可以解决一些问题和提升性能：
>
>+ 提高吞吐量【并行消费，允许多个消费者并行处理来自多个分区的消息】
>
>+ 负载均衡【将主题的分区均匀地分配给消费者组】
>
>  
>
>
>**消费者组是逻辑上的一个订阅者**，



### 讲述一下分区的分配以及再平衡

> 挂掉后45s后才能触发再平衡

消费者组的分区分配策略：

1）Range（对分区和消费者排序，通过取余计算每个消费者要消费的个数，按照分区的顺序取对应消费分区的个数）

2）RoundRobin（轮循）

3）Sticky（粘性）

4）CooperativeSticky（合作式粘性）

**默认的策略是Range+CooperativeSticky**，可以多个分区策略混用



> **默认的策略是Range+CooperativeSticky**，也算是默认使用Range策略
>
> **Range容易产生数据倾斜**【如果只有一个topic，消费者可能会多消费一个分区，但是当topic有很多时，消费者就会多消费很多分区】
>
> RoundRobin轮循，是吧所有的partition和所有的consumer都列出来，按照hashcode排序，通过轮循算法分配【不会出现数据倾斜】





### 讲一下offset

offset有两种提交方式：

1）自动提交【基于时间提交的，难以把握offset提交的时机】

enable.auto.commit：是否开启自动提交offset功能，**默认是true** 

auto.commit.interval.ms：自动提交offset的时间间隔，默认是5s



2）手动提交

+ 同步提交【必须等待offset提交完毕后再去消费下一批数据】

+ 异步提交（没有失败重试机制，可能会提交失败）

#### 当 Kafka 中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量 时（例如该数据已被删除），该怎么办？

指定offset消费：

auto.offset.reset = earliest | latest | none 默认是 latest。

（1）earliest：自动将偏移量重置为最早的偏移量，--from-beginning。 

（2）latest（默认值）：自动将偏移量重置为最新偏移量。 

（3）none：如果未找到消费者组的先前偏移量，则向消费者抛出异常。 



#### 指定时间消费

需求：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间消费前一天的数据，怎么处理？



### 漏消费和重复消费

重复消费：已经消费了数据，但是 offset 没提交。

漏消费：先提交 offset 后消费，有可能会造成数据的漏消费。





















# redis

 Lua是一种轻量级、高效的脚本语言,具有可扩展性和可嵌入性 

> 使用eval 通过lua脚本去操作批量数据：
>
> EVAL "local keys = redis.call('keys', 'DIM*'); for i=1,#keys,5000 do redis.call('del', unpack(keys, i, math.min(i+4999, #keys))) end" 0
>
> 







# Zookeeper

协调分布式系统。





# ElasticSearch

> ES是一个实时的分布式搜索和分析引擎。

es被认为是一种OLAP数据库。

原因：

+ 多维度数据分析
+ 实时性
+ 分布式架构
+ 弹性扩展
+ 文本搜索能力



# 小海豚

dolphinscheduler： 任务调度和工作流管理系统 

Azkaban： 任务调度和工作流管理系统 

